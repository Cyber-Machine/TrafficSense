{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Walkthrough through TrafficSense\n",
        "\n",
        "- A simple run of [TrafficSense](https://github.com/Cyber-Machine/TrafficSense).\n",
        "- It can classify four Indian police hand signals trained on custom augmented dataset and achieves a accuracy of ~86%.\n",
        "\n",
        "- Detecting poses is achieved via the movenet-thunder model which is lightweight and enables real-time detection.\n",
        "\n",
        "- Classification is done using a custom layered Neural Network which achieves a accuracy of ~86%.\n",
        "\n",
        "- Run the following cells to test code.\n",
        "\n",
        "- Output video of realtime video is generated under `./TrafficSense/output.mp4` which can be downloaded."
      ],
      "metadata": {
        "id": "CCN3vN1x9Ny3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import dependencies\n",
        "from IPython.display import display, Javascript, Image , HTML\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "import os\n",
        "import sys"
      ],
      "metadata": {
        "id": "RnjsVzUs0kte"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cloning Repo from Github"
      ],
      "metadata": {
        "id": "k6_OuodM_xy8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WyTU-_r0PWn",
        "outputId": "c5df616c-15ae-423a-d6df-ba02a7f62086"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TrafficSense'...\n",
            "remote: Enumerating objects: 59, done.\u001b[K\n",
            "remote: Counting objects: 100% (59/59), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 59 (delta 12), reused 59 (delta 12), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (59/59), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Cyber-Machine/TrafficSense"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Changing directory to the cloned repo"
      ],
      "metadata": {
        "id": "WQzwuqqK_sWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd TrafficSense"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXd274FDVnlt",
        "outputId": "06a7c058-63f6-410f-9ddc-84d549bb3b76"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TrafficSense\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SciaL-wdVohV",
        "outputId": "e8e5fc9c-dc99-4dc1-b95b-0cfa7420b34d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.8.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "8d9H0f7YVtb2",
        "outputId": "9e058bae-aa5b-4191-fbcb-e4a06ccdb9a8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting argparse\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 2)) (1.21.6)\n",
            "Collecting opencv-python~=4.5.3.56\n",
            "  Downloading opencv_python-4.5.3.56-cp38-cp38-manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 49.9 MB 109 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=1.3.1 in /usr/local/lib/python3.8/dist-packages (from -r requirements.txt (line 4)) (1.3.5)\n",
            "Collecting tflite-runtime>=2.7.0\n",
            "  Downloading tflite_runtime-2.11.0-cp38-cp38-manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 32.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3.1->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.3.1->-r requirements.txt (line 4)) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.3.1->-r requirements.txt (line 4)) (1.15.0)\n",
            "Installing collected packages: tflite-runtime, opencv-python, argparse\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.6.0.66\n",
            "    Uninstalling opencv-python-4.6.0.66:\n",
            "      Successfully uninstalled opencv-python-4.6.0.66\n",
            "Successfully installed argparse-1.4.0 opencv-python-4.5.3.56 tflite-runtime-2.11.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "argparse",
                  "cv2"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import cv2\n",
        "import utils\n",
        "import numpy \n",
        "from ml import Classifier\n",
        "from ml import Movenet\n",
        "\n",
        "estimation_model = 'movenet_thunder'  \n",
        "tracker_type = 'bounding_box'  # ['keypoint', 'bounding_box']\n",
        "classification_model = 'pose_classifier.tflite'\n",
        "label_file = 'pose_labels.txt'\n",
        "pose_detector = Movenet(estimation_model)\n",
        "print(\"MoveNet Lightning/Thunder model selected.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvjM-Y9NYKY-",
        "outputId": "3a28ecf1-a63e-4b28-e7b8-f99cd1786c87"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoveNet Lightning/Thunder model selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def record_video(filename):\n",
        "    js=Javascript(\"\"\"\n",
        "      async function recordVideo() {\n",
        "        const options = { mimeType: \"video/webm; codecs=vp9\" };\n",
        "        const div = document.createElement('div');\n",
        "        const capture = document.createElement('button');\n",
        "        const stopCapture = document.createElement(\"button\");\n",
        "        \n",
        "        capture.textContent = \"Start Recording\";\n",
        "        capture.style.background = \"orange\";\n",
        "        capture.style.color = \"white\";\n",
        "\n",
        "        stopCapture.textContent = \"Stop Recording\";\n",
        "        stopCapture.style.background = \"red\";\n",
        "        stopCapture.style.color = \"white\";\n",
        "        div.appendChild(capture);\n",
        "\n",
        "        const video = document.createElement('video');\n",
        "        const recordingVid = document.createElement(\"video\");\n",
        "        video.style.display = 'block';\n",
        "\n",
        "        const stream = await navigator.mediaDevices.getUserMedia({audio:true, video: true});\n",
        "      \n",
        "        let recorder = new MediaRecorder(stream, options);\n",
        "        document.body.appendChild(div);\n",
        "        div.appendChild(video);\n",
        "\n",
        "        video.srcObject = stream;\n",
        "        video.muted = true;\n",
        "\n",
        "        await video.play();\n",
        "\n",
        "        google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "        await new Promise((resolve) => {\n",
        "          capture.onclick = resolve;\n",
        "        });\n",
        "        recorder.start();\n",
        "        capture.replaceWith(stopCapture);\n",
        "\n",
        "        await new Promise((resolve) => stopCapture.onclick = resolve);\n",
        "        recorder.stop();\n",
        "        let recData = await new Promise((resolve) => recorder.ondataavailable = resolve);\n",
        "        let arrBuff = await recData.data.arrayBuffer();\n",
        "        \n",
        "        // stop the stream and remove the video element\n",
        "        stream.getVideoTracks()[0].stop();\n",
        "        div.remove();\n",
        "\n",
        "        let binaryString = \"\";\n",
        "        let bytes = new Uint8Array(arrBuff);\n",
        "        bytes.forEach((byte) => {\n",
        "          binaryString += String.fromCharCode(byte);\n",
        "        })\n",
        "      return btoa(binaryString);\n",
        "      }\n",
        "    \"\"\")\n",
        "    try:\n",
        "      display(js)\n",
        "      data=eval_js('recordVideo({})')\n",
        "      binary=b64decode(data)\n",
        "      with open(filename,\"wb\") as video_file:\n",
        "        video_file.write(binary)\n",
        "      print(f\"Finished recording video at:{filename}\")\n",
        "    except Exception as err:\n",
        "      print(str(err))"
      ],
      "metadata": {
        "id": "mkBObPFMcI8e"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_video(video_path, video_width = 600):\n",
        "  \n",
        "  video_file = open(video_path, \"r+b\").read()\n",
        "\n",
        "  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
        "  return HTML(f\"\"\"<video width={video_width} controls><source src=\"{video_url}\"></video>\"\"\")"
      ],
      "metadata": {
        "id": "_NrQVrAYp8m1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_path = \"test.mp4\"\n",
        "record_video(video_path)"
      ],
      "metadata": {
        "id": "JDOQ_EhUp_cA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_video(video_path)"
      ],
      "metadata": {
        "id": "Yd0sxqcFp_rl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "Ds1Fdw_CqAjV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row_size = 20  # pixels\n",
        "left_margin = 24  # pixels\n",
        "text_color = (255, 0, 0)  # Blue\n",
        "font_size = 1\n",
        "font_thickness = 3\n",
        "max_detection_results = 2\n",
        "fps_avg_frame_count = 10"
      ],
      "metadata": {
        "id": "UjZnp1sUrQW_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture(video_path)\n",
        "fourcc = cv2.VideoWriter_fourcc('F','M','P','4')\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "res = (int(width), int(height))\n",
        "last_image = None\n",
        "out = cv2.VideoWriter('./output.mp4', fourcc, 20.0, res)\n",
        "\n",
        "while cap.isOpened():\n",
        "    success, image = cap.read()\n",
        "    if image is None :\n",
        "      print('Done')\n",
        "      break;\n",
        "    \n",
        "    image = cv2.flip(image, 1)\n",
        "\n",
        "    list_persons = [pose_detector.detect(image)]\n",
        "    image = utils.visualize(image, list_persons)\n",
        "\n",
        "\n",
        "\n",
        "    if classification_model:\n",
        "            classifier = Classifier(classification_model, label_file)\n",
        "            detection_results_to_show = min(max_detection_results, len(classifier.pose_class_names))\n",
        "            # Run pose classification.\n",
        "            prob_list = classifier.classify_pose(list_persons[0])\n",
        "\n",
        "            scores = []\n",
        "            # Show classification results on the image.\n",
        "            for i in range(detection_results_to_show):\n",
        "                class_name = prob_list[i].label\n",
        "        \n",
        "                probability = round(prob_list[i].score, 2)\n",
        "                scores.append(probability)\n",
        "            \n",
        "            class_name = prob_list[numpy.argmax(scores)].label\n",
        "            cv2.putText(image, class_name, (75,50), cv2.FONT_HERSHEY_DUPLEX, font_size, text_color, font_thickness)\n",
        "            out.write(image)\n",
        "            last_image = image\n",
        "out.release()\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "0RUCAaBrqpk5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2_imshow(last_image)"
      ],
      "metadata": {
        "id": "GQKMJMF727ea"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The video is saved as `output.mp4` in this directory."
      ],
      "metadata": {
        "id": "MBOJJeVv5rfn"
      }
    }
  ]
}